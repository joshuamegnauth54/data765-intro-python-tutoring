{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Cross tabulations and generalized linear models using [Samplics](https://github.com/samplics-org/samplics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from typing import TypeAlias, Literal\n",
    "from samplics.categorical import CrossTabulation\n",
    "from samplics.regression.glm import SurveyGLM\n",
    "\n",
    "gss: pd.DataFrame = pd.read_csv(\"data/Theo_extract_3-20-2023.csv\")\n",
    "gss_saf: pd.DataFrame = pd.read_csv(\"data/Safiya_extract_3-20-2023.csv\")\n",
    "\n",
    "# --------------------------------\n",
    "# --- Quick clean up (ignore) ----\n",
    "# --------------------------------\n",
    "# Any number type (lazy)\n",
    "Number: TypeAlias = np.number | float | pd.Int64Dtype\n",
    "\n",
    "\n",
    "def recode_party(partyid: Number) -> Literal[\"Democrat\", \"Republican\", \"Other\", pd.NA]:\n",
    "    \"\"\"Recode and collapse GSS' `partyid` from numbers to a few strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    partyid : Number\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Literal[\"Democrat\", \"Republican\", \"Other\", pd.NA]\n",
    "    \"\"\"\n",
    "\n",
    "    match partyid:\n",
    "        case _ if pd.isna(partyid):\n",
    "            return pd.NA\n",
    "        case 0 | 1 | 2:\n",
    "            return \"Democrat\"\n",
    "        case 4 | 5 | 6:\n",
    "            return \"Republican\"\n",
    "        case 3 | 7:\n",
    "            return \"Other\"\n",
    "        case _:\n",
    "            return pd.NA\n",
    "\n",
    "\n",
    "def recode_degree(degree: Number) -> Literal[\"No degree\", \"HS or assoc\", \"College\"]:\n",
    "    \"\"\"Recode and collapse degree into strings with less categories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    degree : Number\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Literal[\"No degree\", \"HS or assoc\", \"College\"]\n",
    "    \"\"\"\n",
    "\n",
    "    match degree:\n",
    "        case _ if pd.isna(degree):\n",
    "            return pd.NA\n",
    "        case 0:\n",
    "            return \"No degree\"\n",
    "        case 1 | 2:\n",
    "            return \"HS or assoc\"\n",
    "        case 3 | 4:\n",
    "            return \"College\"\n",
    "        case _:\n",
    "            return pd.NA\n",
    "\n",
    "\n",
    "# R's political party\n",
    "gss_saf[\"partyid\"] = gss_saf[\"partyid\"].map(recode_party).astype(\"category\")\n",
    "\n",
    "# Obvious features\n",
    "# gss_saf[\"age\"] = gss_saf[\"age\"].astype(\"Int64\")\n",
    "gss_saf[\"degree\"] = (\n",
    "    gss_saf[\"degree\"].astype(\"Int64\").map(recode_degree).astype(\"category\")\n",
    ")\n",
    "gss_saf[\"sex\"] = (\n",
    "    gss_saf[\"sex\"].astype(\"Int64\").map({1: \"Male\", 2: \"Female\"}).astype(\"category\")\n",
    ")\n",
    "\n",
    "# Does R speak a language other than English or Spanish?\n",
    "gss_saf[\"othlang\"] = (\n",
    "    gss_saf[\"othlang\"].astype(\"Int64\").map({1: \"Yes\", 2: \"No\"}).astype(\"category\")\n",
    ")\n",
    "\n",
    "# Immigration should be decreased (recoded from letin1a)\n",
    "gss_saf[\"decrease_imm\"] = (\n",
    "    gss_saf[\"decrease_imm\"].astype(\"Int64\").map({1: \"Yes\", 0: \"No\"}).astype(\"category\")\n",
    ")\n",
    "\n",
    "# How important is it for respondent's children to be able to think for themselves?\n",
    "gss[\"thnkself\"] = (\n",
    "    gss[\"thnkself\"]\n",
    "    .astype(\"Int64\")\n",
    "    .map({1: \"Most\", 2: \"Second\", 3: \"Third\", 4: \"Fourth\", 5: \"Last\"})\n",
    "    .astype(\"category\")\n",
    ")\n",
    "\n",
    "# Does the respondent believe in life after death?\n",
    "gss[\"postlife\"] = gss[\"postlife\"].map({1: \"Yes\", 2: \"No\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-tabulation of postlife and thnkself\n",
      " Number of strata: 1\n",
      " Number of PSUs: 2\n",
      " Number of observations: 8167\n",
      " Degrees of freedom: 1.00\n",
      "\n",
      " postlife thnkself  proportion  stderror  lower_ci  upper_ci\n",
      "      No   Fourth    0.030365  0.002184  0.012053  0.074401\n",
      "      No     Last    0.010181  0.000394  0.006219  0.016625\n",
      "      No     Most    0.092465  0.001289  0.077340  0.110196\n",
      "      No   Second    0.034407  0.000216  0.031767  0.037258\n",
      "      No    Third    0.031475  0.000818  0.022583  0.043711\n",
      "     Yes   Fourth    0.140978  0.009139  0.059188  0.299778\n",
      "     Yes     Last    0.037669  0.000800  0.028721  0.049265\n",
      "     Yes     Most    0.326757  0.003157  0.287977  0.368060\n",
      "     Yes   Second    0.157055  0.000825  0.146851  0.167829\n",
      "     Yes    Third    0.138646  0.002275  0.112183  0.170156\n",
      "\n",
      "Pearson (with Rao-Scott adjustment):\n",
      "\tUnadjusted - chi2(4): 19.9821 with p-value of 0.0005\n",
      "\tAdjusted - F(1.00, 1.00): 6.1194  with p-value of 0.2446\n",
      "\n",
      "  Likelihood ratio (with Rao-Scott adjustment):\n",
      "\t Unadjusted - chi2(4): 19.9564 with p-value of 0.0005\n",
      "\t Adjusted - F(1.00, 1.00): 6.1115  with p-value of 0.2447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tab_thnk_post = CrossTabulation(\"proportion\")\n",
    "tab_thnk_post.tabulate(\n",
    "    vars=gss[[\"postlife\", \"thnkself\"]],\n",
    "    samp_weight=gss[\"wtssall\"],\n",
    "    # There isn't any stratification for the variables used\n",
    "    # ...or there's only one PSU. Something like that.\n",
    "    # stratum=gss[\"vstrat\"],\n",
    "    psu=gss[\"vpsu\"],\n",
    "    remove_nan=True,\n",
    ")\n",
    "\n",
    "print(tab_thnk_post)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9045,2) (9045,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# I wish samplics wasn't incomplete.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m glm_imm \u001b[39m=\u001b[39m SurveyGLM()\n\u001b[1;32m---> 15\u001b[0m glm_imm\u001b[39m.\u001b[39;49mestimate(\n\u001b[0;32m     16\u001b[0m     y\u001b[39m=\u001b[39;49my_feature,\n\u001b[0;32m     17\u001b[0m     x\u001b[39m=\u001b[39;49mX_imm_dummies,\n\u001b[0;32m     18\u001b[0m     samp_weight\u001b[39m=\u001b[39;49mgss_saf[\u001b[39m\"\u001b[39;49m\u001b[39mwtssnrps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     19\u001b[0m     \u001b[39m# stratum=saf_gss[\"vstrat\"],\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m     psu\u001b[39m=\u001b[39;49mgss_saf[\u001b[39m\"\u001b[39;49m\u001b[39mvpsu\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     21\u001b[0m     remove_nan\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m results_imm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m     25\u001b[0m     [glm\u001b[39m.\u001b[39mbeta, \u001b[39m*\u001b[39mglm\u001b[39m.\u001b[39mcov_beta], columns\u001b[39m=\u001b[39mX_features, index\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcoef\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mX_features]\n\u001b[0;32m     26\u001b[0m )\u001b[39m.\u001b[39mT\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(results_imm)\n",
      "File \u001b[1;32m~/.cache/pypoetry/virtualenvs/data765-tutoring-vE7c8LV9-py3.10/lib/python3.10/site-packages/samplics/regression/glm.py:95\u001b[0m, in \u001b[0;36mSurveyGLM.estimate\u001b[1;34m(self, y, x, samp_weight, stratum, psu, fpc, remove_nan)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfpc \u001b[39m=\u001b[39m fpc\n\u001b[0;32m     94\u001b[0m glm_model \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mGLM(endog\u001b[39m=\u001b[39m_y, exog\u001b[39m=\u001b[39m_x, var_weights\u001b[39m=\u001b[39m_samp_weight)\n\u001b[1;32m---> 95\u001b[0m glm_results \u001b[39m=\u001b[39m glm_model\u001b[39m.\u001b[39;49mfit()\n\u001b[0;32m     97\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calculate_g(\n\u001b[0;32m     98\u001b[0m     samp_weight\u001b[39m=\u001b[39m_samp_weight,\n\u001b[0;32m     99\u001b[0m     resid\u001b[39m=\u001b[39mglm_results\u001b[39m.\u001b[39mresid_response,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     glm_scale\u001b[39m=\u001b[39mglm_results\u001b[39m.\u001b[39mscale,\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    107\u001b[0m d \u001b[39m=\u001b[39m glm_results\u001b[39m.\u001b[39mcov_params()\n",
      "File \u001b[1;32m~/.cache/pypoetry/virtualenvs/data765-tutoring-vE7c8LV9-py3.10/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:1075\u001b[0m, in \u001b[0;36mGLM.fit\u001b[1;34m(self, start_params, maxiter, method, tol, scale, cov_type, cov_kwds, use_t, full_output, disp, max_start_irls, **kwargs)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[39mif\u001b[39;00m cov_type\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meim\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1074\u001b[0m         cov_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnonrobust\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1075\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_irls(start_params\u001b[39m=\u001b[39;49mstart_params, maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[0;32m   1076\u001b[0m                           tol\u001b[39m=\u001b[39;49mtol, scale\u001b[39m=\u001b[39;49mscale, cov_type\u001b[39m=\u001b[39;49mcov_type,\n\u001b[0;32m   1077\u001b[0m                           cov_kwds\u001b[39m=\u001b[39;49mcov_kwds, use_t\u001b[39m=\u001b[39;49muse_t, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1078\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optim_hessian \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39moptim_hessian\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~/.cache/pypoetry/virtualenvs/data765-tutoring-vE7c8LV9-py3.10/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:1188\u001b[0m, in \u001b[0;36mGLM._fit_irls\u001b[1;34m(self, start_params, maxiter, tol, scale, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     lin_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(wlsexog, start_params) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset_exposure\n\u001b[0;32m   1187\u001b[0m     mu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfamily\u001b[39m.\u001b[39mfitted(lin_pred)\n\u001b[1;32m-> 1188\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_scale(mu)\n\u001b[0;32m   1189\u001b[0m dev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfamily\u001b[39m.\u001b[39mdeviance(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog, mu, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_weights,\n\u001b[0;32m   1190\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreq_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale)\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(dev):\n",
      "File \u001b[1;32m~/.cache/pypoetry/virtualenvs/data765-tutoring-vE7c8LV9-py3.10/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:783\u001b[0m, in \u001b[0;36mGLM.estimate_scale\u001b[1;34m(self, mu)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m1.\u001b[39m\n\u001b[0;32m    782\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 783\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_x2_scale(mu)\n\u001b[0;32m    785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaletype, \u001b[39mfloat\u001b[39m):\n\u001b[0;32m    786\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaletype)\n",
      "File \u001b[1;32m~/.cache/pypoetry/virtualenvs/data765-tutoring-vE7c8LV9-py3.10/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:803\u001b[0m, in \u001b[0;36mGLM._estimate_x2_scale\u001b[1;34m(self, mu)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_x2_scale\u001b[39m(\u001b[39mself\u001b[39m, mu):\n\u001b[1;32m--> 803\u001b[0m     resid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mpower(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendog \u001b[39m-\u001b[39;49m mu, \u001b[39m2\u001b[39;49m) \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miweights\n\u001b[0;32m    804\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(resid \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfamily\u001b[39m.\u001b[39mvariance(mu)) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_resid\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9045,2) (9045,) "
     ]
    }
   ],
   "source": [
    "# Explicitly drop NAs because remove_nan doesn't do it for some reason\n",
    "gss_saf = gss_saf.dropna()\n",
    "\n",
    "# Variable names for features\n",
    "X_features = [\"year\", \"age\", \"degree\", \"sex\", \"partyid\", \"coninc\"]\n",
    "X_imm_dummies = pd.get_dummies(gss_saf[X_features], drop_first=True)\n",
    "X_imm_dummies = sm.add_constant(X_imm_dummies)\n",
    "\n",
    "# Target feature\n",
    "y_feature = pd.get_dummies(gss_saf[\"decrease_imm\"])\n",
    "\n",
    "# I wish samplics wasn't incomplete.\n",
    "# Fit the model\n",
    "glm_imm = SurveyGLM()\n",
    "glm_imm.estimate(\n",
    "    y=y_feature,\n",
    "    x=X_imm_dummies,\n",
    "    samp_weight=gss_saf[\"wtssnrps\"],\n",
    "    # stratum=saf_gss[\"vstrat\"],\n",
    "    psu=gss_saf[\"vpsu\"],\n",
    "    remove_nan=True,\n",
    ")\n",
    "\n",
    "results_imm = pd.DataFrame(\n",
    "    [glm.beta, *glm.cov_beta], columns=X_features, index=[\"coef\", *X_features]\n",
    ").T\n",
    "\n",
    "print(results_imm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          ['No', 'Yes']   No. Observations:                 9045\n",
      "Model:                            GLM   Df Residuals:                     9036\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -5462.6\n",
      "Date:                Fri, 24 Mar 2023   Deviance:                       10925.\n",
      "Time:                        01:09:49   Pearson chi2:                 8.77e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):             0.1048\n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const               -160.0024     12.536    -12.764      0.000    -184.572    -135.433\n",
      "year                   0.0804      0.006     12.914      0.000       0.068       0.093\n",
      "age                   -0.0141      0.001    -10.614      0.000      -0.017      -0.012\n",
      "coninc              1.045e-06   5.77e-07      1.811      0.070   -8.62e-08    2.18e-06\n",
      "degree_HS or assoc    -0.6870      0.058    -11.912      0.000      -0.800      -0.574\n",
      "degree_No degree      -0.5486      0.087     -6.282      0.000      -0.720      -0.377\n",
      "sex_Male               0.0957      0.046      2.066      0.039       0.005       0.186\n",
      "partyid_Other         -0.5114      0.061     -8.365      0.000      -0.631      -0.392\n",
      "partyid_Republican    -1.2019      0.053    -22.572      0.000      -1.306      -1.098\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Binomial regression\n",
    "glm_imm = sm.GLM(\n",
    "    y_feature,\n",
    "    X_imm_dummies,\n",
    "    family=sm.families.Binomial(),\n",
    "    var_weights=gss_saf[\"wtssnrps\"],\n",
    "    missing=\"drop\",\n",
    ")\n",
    "\n",
    "results_imm = glm_imm.fit()\n",
    "print(results_imm.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
